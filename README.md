# AI Development Workflow: Predicting Student Dropout Rates 🎓🧠

## 📌 Project Overview
This project applies the **AI Development Workflow** to a real-world education problem: **predicting student dropout rates** using historical data. The goal is to build a machine learning model that can help educational institutions identify at-risk students early and intervene effectively.

---

## 🧾 Problem Statement
High student dropout rates negatively impact both learners and institutions. Using AI, we aim to develop a model that predicts dropout likelihood based on demographic and academic data.

---

## 🎯 Objectives
- Predict whether a student is at risk of dropping out.
- Help institutions allocate support resources efficiently.
- Reduce dropout rates and improve retention.

---

## 👥 Stakeholders
- School Administrators
- Academic Counselors

---

## ✅ Key Performance Indicator (KPI)
- Accuracy and F1-Score of the model in predicting dropout risk.

---

## 📊 Dataset
- **Source**: Kaggle / Simulated educational data
- **Features**: Age, gender, GPA, attendance, engagement level, etc.
- **Target**: Dropout (Yes/No)

---

## 🔧 Tools & Libraries Used
- Google Colab
- Python (Pandas, NumPy)
- Scikit-learn
- Matplotlib & Seaborn
- Jupyter Notebook

---

## 📁 Project Structure
AI_Development_Workflow/
├── AI_Development_Workflow.ipynb # Main Colab notebook
├── README.md # This file
├── report.pdf # Final report with answers & reflections
├── screenshots/ # Screenshots of model outputs

---

## 🚀 Running the Project
1. Open the `.ipynb` notebook in Google Colab.
2. Run all cells sequentially.
3. The model is trained and evaluated in the final cells.
4. Output includes accuracy, confusion matrix, and F1-score.

---

## 📈 Model Evaluation
- Model: Random Forest Classifier
- Accuracy: **~91%**
- F1 Score: **~89%**

---

## 📌 Ethical Considerations
- Addressed dataset bias (e.g., gender imbalance)
- Reflected on model fairness and interpretability
- Discussed use of IBM AI Fairness 360 in report

---

## ✍️ Author
- **Name**: Caren Rayon  
  

---

## 📎 Report & Submission
- The PDF report is included in this repo and published on the PLP Community platform.
- It contains all theoretical answers, screenshots, and ethical analysis.

---

## 📷 Screenshots
Screenshots of output graphs, confusion matrix, and model summary are available in the `screenshots/` folder and embedded in the report.

---

## ✅ Status
**✅ Completed** – All code executed successfully, report written and submitted, screenshots captured.


